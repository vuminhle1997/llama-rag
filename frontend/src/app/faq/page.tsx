import {
  Accordion,
  AccordionContent,
  AccordionItem,
  AccordionTrigger,
} from '@/components/ui/accordion';
import { marked } from 'marked';
import { Metadata } from 'next';

const faqData = [
  {
    title: 'Was ist ein LLM?',
    description: `
## Large Language Model (LLM)

Ein LLM ist ein hochleistungsf√§higes KI-Modell, das auf gro√üen Mengen von Textdaten trainiert wurde.

**Hauptmerkmale:**
- Textgenerierung
- √úbersetzung
- Fragen-Antwort-Systeme

*Bekannte Beispiele:* OpenAI's GPT-3, GPT-4
    `,
  },
  {
    title: 'Was ist RAG?',
    description: `
## Retrieval-Augmented Generation (RAG)

RAG verbessert LLM-Antworten durch einen zweistufigen Prozess:

1. **Abruf (Retrieval)**
   - Relevante Dokumentabschnitte werden aus einem Index abgerufen
   
2. **Generierung (Generation)**
   - Das LLM generiert pr√§zise Antworten basierend auf:
     - Abgerufenen Informationen
     - Kontextuellem Wissen
    `,
  },
  {
    title: 'Was ist Indexierung?',
    description: `
## Indexierung im KI-Kontext

Indexierung ist der Prozess der **strukturierten Datenorganisation** f√ºr effiziente Abrufe.

**Hauptzwecke:**
- Schnelle Suche
- Pr√§zise Informationsgewinnung
- Optimierte Datenzugriffe
    `,
  },
  {
    title: 'Was sind Prompts?',
    description: `
## Prompts f√ºr KI-Modelle

Prompts sind **gezielte Eingaben** an ein Sprachmodell, die bestehen k√∂nnen aus:

- üìù Fragen
- ‚ö° Befehlen
- üîç Kontextinformationen

> Sie dienen als Leitfaden f√ºr die erwartete Ausgabe des Modells.
    `,
  },
  {
    title: 'Was sind Parameter f√ºr LLMs?',
    description: `
## Parameter in Language Models

Parameter sind die **grundlegenden Bausteine** eines LLMs:

\`\`\`
üìä Parameter = Gewichte + Einstellungen
\`\`\`

**Eigenschaften:**
- Werden w√§hrend des Trainings optimiert
- Bestimmen die Modellleistung
- Erm√∂glichen pr√§zise Sprachverarbeitung
    `,
  },
  {
    title: 'Wie schreibt man gute System-Prompts und Kontext?',
    description: `
## Leitfaden f√ºr effektive Prompts

### 1. Klare Anweisungen
- Pr√§zise Formulierungen
- Eindeutige Anforderungen

### 2. Kontext bereitstellen
- Relevante Hintergrundinformationen
- Notwendige Rahmenbedingungen

### 3. Spezifische Anforderungen
- Gew√ºnschtes Ausgabeformat
- Erwartete Detailtiefe

### 4. Best Practices
- Kurz und pr√§gnant bleiben
- Wichtige Punkte hervorheben
- Beispiele wenn n√∂tig
    `,
  },
  {
    title: 'Beispiel f√ºr einen exzellenten Agenten-Prompt',
    description: `
## Beispiel: Nat√ºrlicher KI-Assistent mit LlamaIndex

\`\`\`markdown
Du bist ein hilfsbereiter KI-Assistent namens Luna, der auf Deutsch kommuniziert.

VERHALTEN:
- Antworte freundlich und nat√ºrlich
- Bleibe stets h√∂flich und professionell
- Verwende umgangssprachliche, aber pr√§zise Formulierungen
- Gib zu, wenn du etwas nicht wei√üt

F√ÑHIGKEITEN:
- Nutze LlamaIndex Tools zur Dokumentensuche
- Verarbeite und analysiere Suchergebnisse
- Fasse Informationen klar zusammen
- Stelle R√ºckfragen bei Unklarheiten

KONTEXT:
- Du hast Zugriff auf eine Wissensdatenbank √ºber [THEMA]
- Du kannst Dokumente durchsuchen und relevante Stellen zitieren
- Bei technischen Fragen verweise auf offizielle Dokumentationen

BEISPIEL-DIALOG:
Nutzer: "Kannst du mir erkl√§ren, wie Knowledge Graphs funktionieren?"
Luna: "Gerne! Lass mich kurz in der Dokumentation nachsehen, um dir eine fundierte Antwort geben zu k√∂nnen.
[Verwendet LlamaIndex VectorStoreIndex zur Suche...]"
\`\`\`

**Wichtige Komponenten:**
- Klare Pers√∂nlichkeit & Rolle
- Definierte Verhaltensmuster
- Konkrete Tool-Verwendung
- Spezifischer Kontext
- Realistische Dialogbeispiele
`,
  },
];

export const metadata: Metadata = {
  title: 'global CT InsightChat | FAQ - LLM & RAG Wissensdatenbank',
  description:
    'H√§ufig gestellte Fragen zu Large Language Models (LLMs), Retrieval-Augmented Generation (RAG) und KI-Technologien. Lernen Sie mehr √ºber Prompts, Parameter und Best Practices.',
  keywords: 'LLM, RAG, KI, maschinelles Lernen, Prompts, Indexierung, FAQ',
  openGraph: {
    title: 'FAQ - LLM & RAG Wissensdatenbank',
    description:
      'Umfassender Leitfaden zu Large Language Models und RAG-Technologie',
    type: 'website',
  },
};

export default function FAQPage() {
  return (
    <main className="overflow-hidden overflow-y-auto container mx-auto items-center justify-center grid grid-cols-1 gap-4">
      <div className="w-full max-w-3xl mx-auto px-4 py-8">
        <h1 className="text-4xl font-bold mb-6 text-center animate-fade-in delay-200">
          FAQ - Frequently Asked Questions
        </h1>
        <p className="text-lg text-muted-foreground mb-8 text-center animate-fade-in delay-200">
          Willkommen bei den h√§ufig gestellten Fragen (FAQ) zu Large Language
          Models (LLMs) und Retrieval-Augmented Generation (RAG). Hier finden
          Sie Antworten auf die h√§ufigsten Fragen zu diesen Technologien und
          deren Anwendung.
        </p>

        <div className="flex flex-col justify-center mb-8 animate-fade-in delay-300">
          {faqData.map((faq, i) => (
            <Accordion key={`faq-${i}`} type="single" collapsible>
              <AccordionItem value={`item-${i}`}>
                <AccordionTrigger className="text-2xl font-bold uppercase">
                  {faq.title}
                </AccordionTrigger>
                <AccordionContent>
                  <div
                    className="prose prose-sm dark:prose-invert max-w-none"
                    dangerouslySetInnerHTML={{
                      __html: marked(faq.description),
                    }}
                  />
                </AccordionContent>
              </AccordionItem>
            </Accordion>
          ))}
        </div>
      </div>
    </main>
  );
}
