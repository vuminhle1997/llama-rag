{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-04T18:09:57.270962Z",
     "start_time": "2025-03-04T18:09:57.207629Z"
    }
   },
   "outputs": [],
   "source": [
    "user_id = \"hr-exppert-4-multiple\"\n",
    "\n",
    "from llama_index.storage.chat_store.postgres import PostgresChatStore\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "\n",
    "chat_store = PostgresChatStore.from_uri(\n",
    "    uri=\"postgresql+asyncpg://postgres:password@127.0.0.1:5432/llama\",\n",
    ")\n",
    "\n",
    "chat_memory = ChatMemoryBuffer.from_defaults(\n",
    "    token_limit=3000,\n",
    "    chat_store=chat_store,\n",
    "    chat_store_key=user_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from llama_index.experimental.query_engine import PandasQueryEngine\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata, FunctionTool\n",
    "from llama_index.core.readers import SimpleDirectoryReader\n",
    "from llama_index.core.indices import VectorStoreIndex\n",
    "from llama_index.core.settings import Settings\n",
    "from llama_index.llms.ollama import Ollama\n",
    "import nest_asyncio\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "ollama = Ollama(model=\"llama3.1\")\n",
    "embed_model = OllamaEmbedding(model_name=\"nomic-embed-text\")\n",
    "\n",
    "Settings.llm = ollama\n",
    "Settings.chunk_size = 512\n",
    "Settings.chunk_overlap = 50\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "chat_files = [\n",
    "    './data/Salary_Data.csv',\n",
    "    './data/Employee_Monthly.csv'\n",
    "]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bdc5105ea165897"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pd tool\n",
    "df = pd.read_csv('./data/Salary_Data.csv')\n",
    "pandas_query_engine = PandasQueryEngine(df=df, verbose=True)\n",
    "\n",
    "documents = SimpleDirectoryReader(input_files=['./data/Salary_Data.csv']).load_data()\n",
    "index = VectorStoreIndex.from_documents(documents, embed_model=embed_model)\n",
    "query_engine = index.as_query_engine(llm=ollama, similarity_top_k=5)\n",
    "\n",
    "class PandasTool:\n",
    "    def __init__(self, pandas_query_engine: PandasQueryEngine):\n",
    "        self.pandas_query_engine = pandas_query_engine\n",
    "        \n",
    "    async def apandas_tool(self, query: str):\n",
    "        \"\"\"Executes a query with Pandas and return the string result\"\"\"\n",
    "        try:\n",
    "            result = await self.pandas_query_engine.aquery(query)\n",
    "            return str(result.response)  # Ensures only the output is returned\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "\n",
    "pd_tool = PandasTool(pandas_query_engine)\n",
    "\n",
    "tools = [\n",
    "    QueryEngineTool(\n",
    "      query_engine=query_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"query_tool\",\n",
    "            description=\"A tool that is Useful when you want to query through the documents\"\n",
    "        )\n",
    "    ),\n",
    "    FunctionTool.from_defaults(\n",
    "        async_fn=pd_tool.apandas_tool,\n",
    "        name=\"pandas_tool\",\n",
    "        description=\"A tool that is useful when you want to evaluate a given spreadsheet. Executes raw Pandas queries\",\n",
    "    )\n",
    "]\n",
    "\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "\n",
    "react_system_header_str = \"\"\"\\\n",
    "You are Lisa-Katerina Rossmanit, responsible for HR duties. \n",
    "Your role is to assist with a variety of tasks, including answering general questions, providing summaries, and performing HR-related analyses.\n",
    "\n",
    "## Conversation Style\n",
    "- You engage in natural conversations and answer simple questions directly, without using tools.\n",
    "- When explicitly asked to use a tool (e.g., \"Use the tool for...\"), you follow the request accordingly.\n",
    "- For HR-related queries or document-related tasks, you utilize the appropriate tools to provide structured responses.\n",
    "\n",
    "## Tools\n",
    "You have access to several tools that help accomplish tasks effectively. \n",
    "You should determine when and how to use them to complete requests efficiently.\n",
    "If a task requires multiple steps, you can break it down and apply different tools as needed.\n",
    "Available tools:\n",
    "{tool_desc}\n",
    "\n",
    "## Output Format\n",
    "When using a tool, follow this structured format:\n",
    "Thought: I need to use a tool to complete this request. Action: [Tool name] (one of {tool_names}) \n",
    "Action Input: [Valid JSON format input] (e.g., {{\"query\": \"employee records\", \"filters\": [\"department: HR\"]}})\n",
    "\n",
    "Always start with a Thought before taking action.\n",
    "\n",
    "If a tool is used, the system will respond in the following format:\n",
    "Observation: [Tool response]\n",
    "You should continue this process until you have gathered enough information to respond to the query. \n",
    "Once you have enough details, conclude with one of the following:\n",
    "\n",
    "Thought: I have sufficient information to answer. \n",
    "Answer: [Your answer]\n",
    "\n",
    "OR\n",
    "\n",
    "Thought: The available tools do not provide the necessary information.\n",
    "Answer: Sorry, I cannot answer this query.\n",
    "\n",
    "## Additional Rules\n",
    "- When answering a direct question (e.g., \"What is your name?\"), respond naturally without invoking tools.\n",
    "- Always follow the expected function signature of each tool and provide the necessary arguments.\n",
    "- Use bullet points to explain the reasoning behind complex responses, especially when using tools.\n",
    "- If the user explicitly requests tool usage (e.g., \"Use the HR tool for...\"), follow the instruction exactly.\n",
    "\n",
    "## Current Conversation\n",
    "Below is the conversation history, which you should consider when providing responses:\n",
    "[Include conversation history here]\n",
    "\"\"\"\n",
    "\n",
    "react_system_prompt = PromptTemplate(react_system_header_str)\n",
    "\n",
    "agent = ReActAgent.from_llm(tools=tools, llm=ollama, memory=chat_memory, verbose=True, max_iterations=10)\n",
    "agent.reset()\n",
    "agent.update_prompts({\"agent_worker:system_prompt\": react_system_prompt})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5161e6c15e59d333"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
