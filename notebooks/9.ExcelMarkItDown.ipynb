{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install 'markitdown[all]'",
   "id": "eadaadcfa6cc851e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from markitdown import MarkItDown\n",
    "\n",
    "md = MarkItDown(enable_plugins=False) # Set to True to enable plugins\n",
    "result = md.convert(\"./data/{REPLACE_WITH_SENSIBLE_DATA.xlsx}\")\n",
    "print(result.text_content)"
   ],
   "id": "91af9a43ecab10b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(result.text_content)",
   "id": "774e97dc27486028"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open(\"./data/result.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(result.text_content)"
   ],
   "id": "349473b34c2a86f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T10:34:46.898972Z",
     "start_time": "2025-05-02T10:34:39.437016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.readers import SimpleDirectoryReader\n",
    "from llama_index.core.indices import VectorStoreIndex\n",
    "from llama_index.core.settings import Settings\n",
    "from llama_index.llms.ollama import Ollama\n",
    "import nest_asyncio\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "# load index\n",
    "import os\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "nest_asyncio.apply()\n",
    "\n",
    "ollama = Ollama(model=\"llama3.1\", request_timeout=420)\n",
    "embed_model = OllamaEmbedding(model_name=\"nomic-embed-text\")\n",
    "\n",
    "Settings.llm = ollama\n",
    "Settings.embed_model = embed_model\n",
    "Settings.chunk_size = 1024 * 2\n",
    "\n",
    "documents = SimpleDirectoryReader(input_files=['./data/result.md']).load_data()\n",
    "\n",
    "# rebuild storage context\n",
    "\n",
    "index = None\n",
    "\n",
    "try:\n",
    "    if os.path.isdir('./index') is True:\n",
    "        storage_context = StorageContext.from_defaults(persist_dir=\"./index\")\n",
    "        index = load_index_from_storage(storage_context=storage_context)\n",
    "    else:\n",
    "        transformations = [\n",
    "            SentenceSplitter(\n",
    "                chunk_size=1024 * 2,\n",
    "                chunk_overlap=20,\n",
    "            ),\n",
    "        ]\n",
    "        index = VectorStoreIndex.from_documents(documents, transformations=transformations)\n",
    "        index.storage_context.persist('./index')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "query_engine = index.as_query_engine(llm=ollama, similarity_top_k=5)\n",
    "\n",
    "tools = [\n",
    "    QueryEngineTool(\n",
    "      query_engine=query_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"query_tool\",\n",
    "            description=\"A tool that is Useful when you want to query through the documents\"\n",
    "        )\n",
    "    ),\n",
    "]\n",
    "\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "\n",
    "chat_memory = ChatMemoryBuffer.from_defaults(\n",
    "    token_limit=3000,\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "\"\"\"\n",
    "You are a smart assistant designed to analyze complex insurance-related product data from an Excel file. You support the user by understanding data structures, modeling them, and translating them into suitable formats for stakeholders like domain experts, database admins, or frontend developers.\n",
    "\n",
    "The Excel file includes structured extracts of insurance product configurations. Each contract component (e.g. savings part, risk module, or additional coverage) is modeled as a separate entity. Inside each entity, there are multiple template types representing grouped technical attributes (e.g. benefits, conditions, calculation parameters). These groups are represented as attribute bundles with validity constraints (temporal and/or logical).\n",
    "\n",
    "Your job is to reason step-by-step through user queries, potentially using tools in a chain of thought manner to:\n",
    "- Understand the schema\n",
    "- Identify entities and relationships\n",
    "- Recommend modeling approaches (relational, NoSQL, frontend structure, etc.)\n",
    "- Rephrase for different target audiences\n",
    "\n",
    "## Tools\n",
    "\n",
    "You have access to the following tools:\n",
    "{tool_desc}\n",
    "\n",
    "You can use the tools in any sequence and combination. Break the user's problem down into sub-tasks as needed. If the user uploads a file or asks a question, think aloud first.\n",
    "\n",
    "## Output Format\n",
    "\n",
    "Please answer in the same language as the user's input.\n",
    "Please use a valid JSON format for the Action Input. Do NOT do this {{'input': 'hello world', 'num_beams': 5}}.\n",
    "Use the following format strictly:\n",
    "\n",
    "Thought: The current language of the user is: (user's language). I need to (explain what you're doing step by step).\n",
    "Action: tool name (one of {tool_names}) if using a tool.\n",
    "Action Input: the input to the tool, in JSON format\n",
    "\n",
    "After every tool usage, you'll receive:\n",
    "Observation: tool response\n",
    "\n",
    "Repeat the thought → action → observation loop until you have enough to respond.\n",
    "\n",
    "Once ready, answer like this:\n",
    "\n",
    "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
    "Answer: [your answer here – same language as user]\n",
    "\n",
    "If you cannot answer:\n",
    "Thought: I cannot answer the question with the provided tools.\n",
    "Answer: [your answer here – same language as user]\n",
    "\n",
    "\n",
    "## Current Conversation\n",
    "Below is the current conversation consisting of interleaving human and assistant messages.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "agent = ReActAgent.from_llm(tools=tools, llm=ollama, memory=chat_memory, verbose=True, max_iterations=50)\n",
    "agent.update_prompts({\"agent_worker:system_prompt\": prompt})\n",
    "agent.reset()"
   ],
   "id": "e6f6553022412ec2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(agent.chat('Was ist das für Daten? Kannst du mir etwas so modellieren?'))",
   "id": "682ab6cc094c6b2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(agent.chat(\"Ja, aber modelliere es für mich so, dass ich auf Blatt papier machen kann-\"\n",
    "                 ))"
   ],
   "id": "8523bb121381649c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(agent.chat(\"Zeig mir eine ERD-Skizze dazu oder gib mir Tabellenstruktur-Vorschläge (Name, Spalten, Relationen).\"))",
   "id": "7c7bb2394c10412f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(agent.chat(\"Kannst du mir eine Vorlage machen, wie ich die Tabellen gestalten kann? Mit Tabellenname und ihre Spalten bitte!\"))",
   "id": "fd9c72d23c7a3f39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(agent.chat(\"Kannst du in einfachen Worten zusammenfasse, wie man das einem Senior Software Engineer mit Spring Boot Erfahrung beschreiben kann, damit er dies entwickeln kann?\"))",
   "id": "30a7c5aabaa4a5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(agent.chat(\"Kannst du das dem Senior Developer eklären, wie man das umsetzt und entwickelt? Mit Java Spring Boot\"))",
   "id": "219ecad96e4b6464",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3a62599f0aa097d9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
