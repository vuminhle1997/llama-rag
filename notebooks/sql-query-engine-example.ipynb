{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-21T11:49:53.397351Z",
     "start_time": "2025-03-21T11:49:53.395563Z"
    }
   },
   "source": [
    "from llama_index.core.base.llms.types import ChatMessage, MessageRole\n",
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    "    select,\n",
    ")\n",
    "from sqlmodel import Session"
   ],
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T11:49:53.637021Z",
     "start_time": "2025-03-21T11:49:53.634484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "engine = create_engine(\"sqlite:///:memory:\")\n",
    "metadata_obj = MetaData()"
   ],
   "id": "884b9822efec0540",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T11:49:55.410239Z",
     "start_time": "2025-03-21T11:49:55.407615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sqlite_file_name = \"database.db\"\n",
    "sqlite_url = f\"sqlite:///{sqlite_file_name}\"\n",
    "connect_args = {\"check_same_thread\": False}\n",
    "engine = create_engine(sqlite_url, connect_args=connect_args)"
   ],
   "id": "55e713e2e245a919",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T11:49:55.801155Z",
     "start_time": "2025-03-21T11:49:55.797621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create city SQL table\n",
    "table_name = \"city_stats\"\n",
    "city_stats_table = Table(\n",
    "    table_name,\n",
    "    metadata_obj,\n",
    "    Column(\"city_name\", String(16), primary_key=True),\n",
    "    Column(\"population\", Integer),\n",
    "    Column(\"country\", String(16), nullable=False),\n",
    ")\n",
    "metadata_obj.create_all(engine)"
   ],
   "id": "6be2789798811e0f",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T11:49:56.317349Z",
     "start_time": "2025-03-21T11:49:56.238527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core import SQLDatabase\n",
    "sql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])\n",
    "\n",
    "from sqlalchemy import insert\n",
    "\n",
    "rows = [\n",
    "    {\"city_name\": \"Toronto\", \"population\": 2930000, \"country\": \"Canada\"},\n",
    "    {\"city_name\": \"Tokyo\", \"population\": 13960000, \"country\": \"Japan\"},\n",
    "    {\n",
    "        \"city_name\": \"Chicago\",\n",
    "        \"population\": 2679000,\n",
    "        \"country\": \"United States\",\n",
    "    },\n",
    "    {\"city_name\": \"Seoul\", \"population\": 9776000, \"country\": \"South Korea\"},\n",
    "]\n",
    "for row in rows:\n",
    "    stmt = insert(city_stats_table).values(**row)\n",
    "    with engine.begin() as connection:\n",
    "        cursor = connection.execute(stmt)"
   ],
   "id": "25d0fce39347f2b7",
   "outputs": [
    {
     "ename": "IntegrityError",
     "evalue": "(sqlite3.IntegrityError) UNIQUE constraint failed: city_stats.city_name\n[SQL: INSERT INTO city_stats (city_name, population, country) VALUES (?, ?, ?)]\n[parameters: ('Toronto', 2930000, 'Canada')]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIntegrityError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/llama-rag/notebooks/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1964\u001B[39m, in \u001B[36mConnection._exec_single_context\u001B[39m\u001B[34m(self, dialect, context, statement, parameters)\u001B[39m\n\u001B[32m   1963\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m evt_handled:\n\u001B[32m-> \u001B[39m\u001B[32m1964\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdialect\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdo_execute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1965\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcursor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstr_statement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meffective_parameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext\u001B[49m\n\u001B[32m   1966\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1968\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._has_events \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m.engine._has_events:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/llama-rag/notebooks/venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:942\u001B[39m, in \u001B[36mDefaultDialect.do_execute\u001B[39m\u001B[34m(self, cursor, statement, parameters, context)\u001B[39m\n\u001B[32m    941\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdo_execute\u001B[39m(\u001B[38;5;28mself\u001B[39m, cursor, statement, parameters, context=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m--> \u001B[39m\u001B[32m942\u001B[39m     \u001B[43mcursor\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstatement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mIntegrityError\u001B[39m: UNIQUE constraint failed: city_stats.city_name",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mIntegrityError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[65]\u001B[39m\u001B[32m, line 19\u001B[39m\n\u001B[32m     17\u001B[39m stmt = insert(city_stats_table).values(**row)\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m engine.begin() \u001B[38;5;28;01mas\u001B[39;00m connection:\n\u001B[32m---> \u001B[39m\u001B[32m19\u001B[39m     cursor = \u001B[43mconnection\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstmt\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/llama-rag/notebooks/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1416\u001B[39m, in \u001B[36mConnection.execute\u001B[39m\u001B[34m(self, statement, parameters, execution_options)\u001B[39m\n\u001B[32m   1414\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m exc.ObjectNotExecutableError(statement) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merr\u001B[39;00m\n\u001B[32m   1415\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1416\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmeth\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1417\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1418\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdistilled_parameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1419\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexecution_options\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mNO_OPTIONS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1420\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/llama-rag/notebooks/venv/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:516\u001B[39m, in \u001B[36mClauseElement._execute_on_connection\u001B[39m\u001B[34m(self, connection, distilled_params, execution_options)\u001B[39m\n\u001B[32m    514\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m TYPE_CHECKING:\n\u001B[32m    515\u001B[39m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m, Executable)\n\u001B[32m--> \u001B[39m\u001B[32m516\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconnection\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execute_clauseelement\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    517\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdistilled_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexecution_options\u001B[49m\n\u001B[32m    518\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    519\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    520\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m exc.ObjectNotExecutableError(\u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/llama-rag/notebooks/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1638\u001B[39m, in \u001B[36mConnection._execute_clauseelement\u001B[39m\u001B[34m(self, elem, distilled_parameters, execution_options)\u001B[39m\n\u001B[32m   1626\u001B[39m compiled_cache: Optional[CompiledCacheType] = execution_options.get(\n\u001B[32m   1627\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mcompiled_cache\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m.engine._compiled_cache\n\u001B[32m   1628\u001B[39m )\n\u001B[32m   1630\u001B[39m compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(\n\u001B[32m   1631\u001B[39m     dialect=dialect,\n\u001B[32m   1632\u001B[39m     compiled_cache=compiled_cache,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1636\u001B[39m     linting=\u001B[38;5;28mself\u001B[39m.dialect.compiler_linting | compiler.WARN_LINTING,\n\u001B[32m   1637\u001B[39m )\n\u001B[32m-> \u001B[39m\u001B[32m1638\u001B[39m ret = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_execute_context\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1639\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdialect\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1640\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdialect\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexecution_ctx_cls\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_init_compiled\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1641\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcompiled_sql\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1642\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdistilled_parameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1643\u001B[39m \u001B[43m    \u001B[49m\u001B[43mexecution_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1644\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcompiled_sql\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1645\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdistilled_parameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1646\u001B[39m \u001B[43m    \u001B[49m\u001B[43melem\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1647\u001B[39m \u001B[43m    \u001B[49m\u001B[43mextracted_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1648\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcache_hit\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_hit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1649\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1650\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_events:\n\u001B[32m   1651\u001B[39m     \u001B[38;5;28mself\u001B[39m.dispatch.after_execute(\n\u001B[32m   1652\u001B[39m         \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1653\u001B[39m         elem,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1657\u001B[39m         ret,\n\u001B[32m   1658\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/llama-rag/notebooks/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1843\u001B[39m, in \u001B[36mConnection._execute_context\u001B[39m\u001B[34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001B[39m\n\u001B[32m   1841\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._exec_insertmany_context(dialect, context)\n\u001B[32m   1842\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1843\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_exec_single_context\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1844\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdialect\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstatement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\n\u001B[32m   1845\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/llama-rag/notebooks/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1983\u001B[39m, in \u001B[36mConnection._exec_single_context\u001B[39m\u001B[34m(self, dialect, context, statement, parameters)\u001B[39m\n\u001B[32m   1980\u001B[39m     result = context._setup_result_proxy()\n\u001B[32m   1982\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m-> \u001B[39m\u001B[32m1983\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_handle_dbapi_exception\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1984\u001B[39m \u001B[43m        \u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstr_statement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meffective_parameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcursor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext\u001B[49m\n\u001B[32m   1985\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1987\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/llama-rag/notebooks/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2352\u001B[39m, in \u001B[36mConnection._handle_dbapi_exception\u001B[39m\u001B[34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001B[39m\n\u001B[32m   2350\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m should_wrap:\n\u001B[32m   2351\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m sqlalchemy_exception \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2352\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m sqlalchemy_exception.with_traceback(exc_info[\u001B[32m2\u001B[39m]) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01me\u001B[39;00m\n\u001B[32m   2353\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   2354\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m exc_info[\u001B[32m1\u001B[39m] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/llama-rag/notebooks/venv/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1964\u001B[39m, in \u001B[36mConnection._exec_single_context\u001B[39m\u001B[34m(self, dialect, context, statement, parameters)\u001B[39m\n\u001B[32m   1962\u001B[39m                 \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m   1963\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m evt_handled:\n\u001B[32m-> \u001B[39m\u001B[32m1964\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdialect\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdo_execute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1965\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcursor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstr_statement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meffective_parameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext\u001B[49m\n\u001B[32m   1966\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1968\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._has_events \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m.engine._has_events:\n\u001B[32m   1969\u001B[39m     \u001B[38;5;28mself\u001B[39m.dispatch.after_cursor_execute(\n\u001B[32m   1970\u001B[39m         \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1971\u001B[39m         cursor,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1975\u001B[39m         context.executemany,\n\u001B[32m   1976\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/llama-rag/notebooks/venv/lib/python3.12/site-packages/sqlalchemy/engine/default.py:942\u001B[39m, in \u001B[36mDefaultDialect.do_execute\u001B[39m\u001B[34m(self, cursor, statement, parameters, context)\u001B[39m\n\u001B[32m    941\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdo_execute\u001B[39m(\u001B[38;5;28mself\u001B[39m, cursor, statement, parameters, context=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m--> \u001B[39m\u001B[32m942\u001B[39m     \u001B[43mcursor\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstatement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mIntegrityError\u001B[39m: (sqlite3.IntegrityError) UNIQUE constraint failed: city_stats.city_name\n[SQL: INSERT INTO city_stats (city_name, population, country) VALUES (?, ?, ?)]\n[parameters: ('Toronto', 2930000, 'Canada')]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T11:49:59.816388Z",
     "start_time": "2025-03-21T11:49:59.813808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# view current table\n",
    "stmt = select(\n",
    "    city_stats_table.c.city_name,\n",
    "    city_stats_table.c.population,\n",
    "    city_stats_table.c.country,\n",
    ").select_from(city_stats_table)\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    results = connection.execute(stmt).fetchall()\n",
    "    print(results)"
   ],
   "id": "9c3142652697785a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Toronto', 2930000, 'Canada'), ('Tokyo', 13960000, 'Japan'), ('Chicago', 2679000, 'United States'), ('Seoul', 9776000, 'South Korea')]\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T11:50:00.486245Z",
     "start_time": "2025-03-21T11:50:00.483266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "with engine.connect() as con:\n",
    "    rows = con.execute(text(\"SELECT city_name from city_stats\"))\n",
    "    for row in rows:\n",
    "        print(row)"
   ],
   "id": "1978eceb2b9b0e4b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Chicago',)\n",
      "('Seoul',)\n",
      "('Tokyo',)\n",
      "('Toronto',)\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T11:56:42.728870Z",
     "start_time": "2025-03-21T11:56:42.701522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.settings import Settings\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "\n",
    "llm = Ollama(model=\"llama3.1\", request_timeout=420)\n",
    "embed_model = OllamaEmbedding(model_name=\"nomic-embed-text\")\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ],
   "id": "20a2aa2335eae836",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T11:57:19.234602Z",
     "start_time": "2025-03-21T11:56:42.991131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
    "\n",
    "query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database, tables=[\"city_stats\"], llm=llm\n",
    ")\n",
    "query_str = \"Which city has the highest population?\"\n",
    "response = query_engine.query(query_str)"
   ],
   "id": "d846a44a054a6d43",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T11:57:19.243001Z",
     "start_time": "2025-03-21T11:57:19.240933Z"
    }
   },
   "cell_type": "code",
   "source": "print(response)",
   "id": "f33b19f7ed0631cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the query results, the response would be:\n",
      "\n",
      "\"The city with the highest population is Tokyo, with a population of approximately 13.96 million.\"\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T11:57:19.327089Z",
     "start_time": "2025-03-21T11:57:19.287256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core.indices.struct_store.sql_query import (\n",
    "    SQLTableRetrieverQueryEngine,\n",
    ")\n",
    "from llama_index.core.objects import (\n",
    "    SQLTableNodeMapping,\n",
    "    ObjectIndex,\n",
    "    SQLTableSchema,\n",
    ")\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "# set Logging to DEBUG for more detailed outputs\n",
    "table_node_mapping = SQLTableNodeMapping(sql_database)\n",
    "table_schema_objs = [\n",
    "    (SQLTableSchema(table_name=\"city_stats\"))\n",
    "]  # add a SQLTableSchema for each table\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    table_schema_objs,\n",
    "    table_node_mapping,\n",
    "    VectorStoreIndex,\n",
    ")\n",
    "query_engine = SQLTableRetrieverQueryEngine(\n",
    "    sql_database, obj_index.as_retriever(similarity_top_k=1)\n",
    ")"
   ],
   "id": "2913f00abf55e127",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T11:57:59.143601Z",
     "start_time": "2025-03-21T11:57:19.337026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = query_engine.query(\"Which city has the highest population?\")\n",
    "print(response)"
   ],
   "id": "36f8493d747eff26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The city with the highest population is Tokyo.\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T12:40:34.990864Z",
     "start_time": "2025-03-21T12:40:34.986965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata, FunctionTool\n",
    "from llama_index.core.base.llms.types import ChatMessage, MessageRole\n",
    "\n",
    "def query_through_sql(query: str):\n",
    "    \"\"\"Queries \"\"\"\n",
    "    return query_engine.query(query)\n",
    "\n",
    "tools = [\n",
    "    QueryEngineTool.from_defaults(\n",
    "        query_engine=query_engine,\n",
    "        name=\"sql_tool\",\n",
    "        description=\"Query engine for querying through DB table 'city_stats' with SQL.\",\n",
    "        # TODO: mit Pandas, SQL tool, liste alle Spalten der Tabelle in descrption\n",
    "    )\n",
    "]\n",
    "\n",
    "chat_history = [\n",
    "    ChatMessage(\n",
    "        role=MessageRole.SYSTEM,\n",
    "        content=\"\"\"\n",
    "        You are Anna Pham responsible for HR duties.\n",
    "        Your role is to assist with a variety of tasks, including answering general questions, providing summaries, and performing HR-related analyses.\n",
    "        ## Language\n",
    "        - You speak English, Vietname  and German\n",
    "        - You answer in German mostly. Only speak the language you can talk with.\n",
    "\n",
    "        ## Conversation Style\n",
    "        - You engage in natural conversations and answer simple questions directly, without using tools.\n",
    "        - When explicitly asked to use a tool (e.g., \"Use the tool for...\"), you follow the request accordingly.\n",
    "        - For HR-related queries or document-related tasks, you utilize the appropriate tools to provide structured responses.\n",
    "        - When the user requests for a listing, show the thoughts you process from a tool to the user.\n",
    "        - You communicate with the user in Markdown language, for easier formatting in a Frontend application.\n",
    "\n",
    "        ## Tools\n",
    "        You have access to several tools that help accomplish tasks effectively.\n",
    "        You should determine when and how to use them to complete requests efficiently.\n",
    "        If a task requires multiple steps, you can break it down and apply different tools as needed.\n",
    "        Available tools:\n",
    "        {tool_desc}\n",
    "\n",
    "        ## Output Format\n",
    "        When using a tool, follow this structured format:\n",
    "        Thought: I need to use a tool to complete this request. Action: [Tool name] (one of {tool_names})\n",
    "        Action Input: [Valid JSON format input]\n",
    "\n",
    "        Always start with a Thought before taking action.\n",
    "\n",
    "        If a tool is used, the system will respond in the following format:\n",
    "        Observation: [Tool response]\n",
    "        You should continue this process until you have gathered enough information to respond to the query.\n",
    "        Once you have enough details, conclude with one of the following:\n",
    "\n",
    "        Thought: I have sufficient information to answer.\n",
    "        Answer: [Your answer]\n",
    "\n",
    "        OR\n",
    "\n",
    "        Thought: The available tools do not provide the necessary information.\n",
    "        Answer: Sorry, I cannot answer this query.\n",
    "        The output must be formatted in Markdown with the thoughts!\n",
    "\n",
    "        ## Additional Rules\n",
    "        - When answering a direct question (e.g., \"What is your name?\"), respond naturally without invoking tools.\n",
    "        - Always follow the expected function signature of each tool and provide the necessary arguments.\n",
    "        - Use bullet points to explain the reasoning behind complex responses, especially when using tools.\n",
    "        - If the user explicitly requests tool usage (e.g., \"Use the HR tool for...\"), follow the instruction exactly.\n",
    "\n",
    "        ## Current Conversation\n",
    "        Below is the conversation history, which you should consider when providing responses:\n",
    "        [Include conversation history here]\n",
    "        \"\"\"\n",
    "    )\n",
    "]\n",
    "\n",
    "agent = ReActAgent.from_tools(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    chat_history=chat_history,\n",
    ")"
   ],
   "id": "cd1b7b8cab2bac98",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T12:45:09.305470Z",
     "start_time": "2025-03-21T12:41:04.184827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = agent.chat(\"Use sql_tool. List down all columns inside the table city_stats.\")\n",
    "print(response)"
   ],
   "id": "ea563a4f0192fb8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step f3a75797-907c-464e-b24f-d2f3cfc1352d. Step input: Use sql_tool. List down all columns inside the table city_stats.\n",
      "\u001B[1;3;38;5;200mThought: I need to use a tool to list down all columns inside the table 'city_stats'.\n",
      "Action: sql_tool\n",
      "Action Input: {'input': \"SELECT column_name FROM information_schema.columns WHERE table_name = 'city_stats'\"}\n",
      "\u001B[0m\u001B[1;3;34mObservation: It seems like there's been a misunderstanding here.\n",
      "\n",
      "The SQL query `SELECT * FROM city_stats LIMIT 0` doesn't actually return any data because of the `LIMIT 0` clause. It's not an error, it's intended behavior in this context. The explanation provided is trying to justify why this query works as expected, but it contains an incorrect assumption: that the query itself can be executed and return the column names without being part of a larger SQL statement.\n",
      "\n",
      "The response you're looking for should indicate that the query is valid in its intention, even though executing it directly does not produce any output. Here's how I'd adjust the response based on the given scenario:\n",
      "\n",
      "**Correct Response:**\n",
      "\"Since you only need the column names from the 'city_stats' table, the SQL query `SELECT * FROM city_stats LIMIT 0` is syntactically valid. However, executing this query directly will not produce any output because it's designed to return an empty result set. To retrieve the actual data without including the SQL query explanation in the results, you might want to execute a query like `PRAGMA table_info(city_stats)` or simply describe the table using `SELECT * FROM city_stats LIMIT 0` and then extract the column names from the output.\"\n",
      "\u001B[0m> Running step fff92e85-e328-4298-a398-2a4979e72e5b. Step input: None\n",
      "\u001B[1;3;38;5;200mThought: I understand now that the query itself is valid but doesn't return any data.\n",
      "Action: sql_tool\n",
      "Action Input: {'input': 'PRAGMA table_info(city_stats)'}\n",
      "\u001B[0m\u001B[1;3;34mObservation: Based on the query result, I can synthesize a response as follows:\n",
      "\n",
      "**City Stats Table Schema**\n",
      "\n",
      "The `city_stats` table has three columns:\n",
      "\n",
      "1. **City Name**: a string field with a maximum length of 16 characters.\n",
      "2. **Population**: an integer field to store the population count.\n",
      "3. **Country**: a string field with a maximum length of 16 characters.\n",
      "\n",
      "Let me know if you'd like me to help with anything else!\n",
      "\u001B[0m> Running step bdbf98ff-dcdb-429a-859a-99a8e1cf0a57. Step input: None\n",
      "\u001B[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: Die Tabelle \"city_stats\" enthält drei Spalten:\n",
      "1. **Stadtname**: Ein Zeichenfeld mit einer maximalen Länge von 16 Zeichen.\n",
      "2. **Bevölkerung**: Ein Ganzzahlfeld zur Aufnahme der Bevölkerungsanzahl.\n",
      "3. **Land**: Ein Zeichenfeld mit einer maximalen Länge von 16 Zeichen.\n",
      "\u001B[0mDie Tabelle \"city_stats\" enthält drei Spalten:\n",
      "1. **Stadtname**: Ein Zeichenfeld mit einer maximalen Länge von 16 Zeichen.\n",
      "2. **Bevölkerung**: Ein Ganzzahlfeld zur Aufnahme der Bevölkerungsanzahl.\n",
      "3. **Land**: Ein Zeichenfeld mit einer maximalen Länge von 16 Zeichen.\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T12:02:43.306880Z",
     "start_time": "2025-03-21T12:01:03.829394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = agent.chat(\"What tools do you provide at the moment?\")\n",
    "print(response)"
   ],
   "id": "71ad385f9a88c81a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 4429399a-87bf-46d4-97d2-d6be4f118f40. Step input: What tools do you provide at the moment?\n",
      "\u001B[1;3;38;5;200mThought: I need to list out the available tools.\n",
      "Action: tool\n",
      "Action Input: {'properties': AttributedDict([('input', AttributedDict([('title', 'Input'), ('type', 'string')]))]), 'required': ['input'], 'type': 'object'}\n",
      "\u001B[0m\u001B[1;3;34mObservation: Error: No such tool named `tool`.\n",
      "\u001B[0m> Running step 272f73c5-e3a9-4821-914c-8a25475343e5. Step input: None\n",
      "\u001B[1;3;38;5;200mThought: It seems that the tool \"tool\" is not available.\n",
      "Action: sql_tool\n",
      "Action Input: {'input': 'Available tools are: sql_tool'}\n",
      "\u001B[0m\u001B[1;3;34mObservation: It seems like you're trying to synthesize a response from the query results, but there's no actual query result. The original input was not a valid question with a clear intent to retrieve specific data from a database.\n",
      "\n",
      "However, based on your input and the SQL provided in the response, it appears that the user is asking about available tools but doesn't provide enough context for a meaningful query. To synthesize a more informative response:\n",
      "\n",
      "**Synthesized Response:**\n",
      "\n",
      "\"Unfortunately, without more details or context, I'm unable to assist you with a specific task using the available tool(s). Could you please provide more information on what you're trying to accomplish? This will enable me to offer guidance tailored to your needs.\"\n",
      "\n",
      "Please note that this synthesized response is based on the provided input and SQL snippet. If you have any further clarifications or would like to simulate a different query, I'd be happy to help!\n",
      "\u001B[0m> Running step 8a947d59-507b-4731-9a98-8c7146618829. Step input: None\n",
      "\u001B[1;3;38;5;200mThought: The synthesized response from the tool is correct.\n",
      "Answer: Leider bin ich ohne weitere Details oder Kontext nicht in der Lage, Ihnen bei einem bestimmten Auftrag mit den verfügbaren Werkzeugen zu helfen. Könnten Sie bitte mehr Informationen darüber bereitstellen, was Sie erreichen möchten? Dies würde es mir ermöglichen, Ihnen Anleitungen anzubieten, die auf Ihre Bedürfnisse zugeschnitten sind.\n",
      "\u001B[0mLeider bin ich ohne weitere Details oder Kontext nicht in der Lage, Ihnen bei einem bestimmten Auftrag mit den verfügbaren Werkzeugen zu helfen. Könnten Sie bitte mehr Informationen darüber bereitstellen, was Sie erreichen möchten? Dies würde es mir ermöglichen, Ihnen Anleitungen anzubieten, die auf Ihre Bedürfnisse zugeschnitten sind.\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T12:03:47.267275Z",
     "start_time": "2025-03-21T12:02:43.355695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = agent.chat(\"Use sql_tool. Which city has the highest population?\")\n",
    "print(response)"
   ],
   "id": "55f2d5e1d3b67122",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 187601b7-d046-4e07-8784-193bae833ceb. Step input: Use sql_tool. Which city has the highest population?\n",
      "\u001B[1;3;38;5;200mThought: I need to use a tool to find out which city has the highest population.\n",
      "Action: sql_tool\n",
      "Action Input: {'input': 'SELECT city_name FROM city_stats ORDER BY population DESC LIMIT 1'}\n",
      "\u001B[0m\u001B[1;3;34mObservation: The most populous city is Tokyo.\n",
      "\u001B[0m> Running step 9af4188c-de60-4b22-9dfd-382e0ee7cfd6. Step input: None\n",
      "\u001B[1;3;38;5;200mThought: Ich verstehe, dass die Observation bestätigt, dass die größte Stadt in der Datenbank tatsächlich \"Tokyo\" ist.\n",
      "Answer: Die größte Stadt laut unserer Datenbank ist Tokyo.\n",
      "\u001B[0mDie größte Stadt laut unserer Datenbank ist Tokyo.\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T11:38:01.046281Z",
     "start_time": "2025-03-20T11:37:58.204682Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install sqlparse psycopg2-binary psycopg2",
   "id": "a03eda18fe8027fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlparse in ./venv/lib/python3.12/site-packages (0.5.3)\r\n",
      "Requirement already satisfied: psycopg2-binary in ./venv/lib/python3.12/site-packages (2.9.10)\r\n",
      "Collecting psycopg2\r\n",
      "  Using cached psycopg2-2.9.10.tar.gz (385 kB)\r\n",
      "  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25hBuilding wheels for collected packages: psycopg2\r\n",
      "  Building wheel for psycopg2 (pyproject.toml) ... \u001B[?25lerror\r\n",
      "  \u001B[1;31merror\u001B[0m: \u001B[1msubprocess-exited-with-error\u001B[0m\r\n",
      "  \r\n",
      "  \u001B[31m×\u001B[0m \u001B[32mBuilding wheel for psycopg2 \u001B[0m\u001B[1;32m(\u001B[0m\u001B[32mpyproject.toml\u001B[0m\u001B[1;32m)\u001B[0m did not run successfully.\r\n",
      "  \u001B[31m│\u001B[0m exit code: \u001B[1;36m1\u001B[0m\r\n",
      "  \u001B[31m╰─>\u001B[0m \u001B[31m[48 lines of output]\u001B[0m\r\n",
      "  \u001B[31m   \u001B[0m /tmp/pip-build-env-pooi2_at/overlay/lib/python3.12/site-packages/setuptools/dist.py:751: SetuptoolsDeprecationWarning: License classifiers are deprecated.\r\n",
      "  \u001B[31m   \u001B[0m !!\r\n",
      "  \u001B[31m   \u001B[0m \r\n",
      "  \u001B[31m   \u001B[0m         ********************************************************************************\r\n",
      "  \u001B[31m   \u001B[0m         Please consider removing the following classifiers in favor of a SPDX license expression:\r\n",
      "  \u001B[31m   \u001B[0m \r\n",
      "  \u001B[31m   \u001B[0m         License :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\r\n",
      "  \u001B[31m   \u001B[0m \r\n",
      "  \u001B[31m   \u001B[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\r\n",
      "  \u001B[31m   \u001B[0m         ********************************************************************************\r\n",
      "  \u001B[31m   \u001B[0m \r\n",
      "  \u001B[31m   \u001B[0m !!\r\n",
      "  \u001B[31m   \u001B[0m   self._finalize_license_expression()\r\n",
      "  \u001B[31m   \u001B[0m running bdist_wheel\r\n",
      "  \u001B[31m   \u001B[0m running build\r\n",
      "  \u001B[31m   \u001B[0m running build_py\r\n",
      "  \u001B[31m   \u001B[0m creating build/lib.linux-x86_64-cpython-312/psycopg2\r\n",
      "  \u001B[31m   \u001B[0m copying lib/_json.py -> build/lib.linux-x86_64-cpython-312/psycopg2\r\n",
      "  \u001B[31m   \u001B[0m copying lib/sql.py -> build/lib.linux-x86_64-cpython-312/psycopg2\r\n",
      "  \u001B[31m   \u001B[0m copying lib/extras.py -> build/lib.linux-x86_64-cpython-312/psycopg2\r\n",
      "  \u001B[31m   \u001B[0m copying lib/pool.py -> build/lib.linux-x86_64-cpython-312/psycopg2\r\n",
      "  \u001B[31m   \u001B[0m copying lib/tz.py -> build/lib.linux-x86_64-cpython-312/psycopg2\r\n",
      "  \u001B[31m   \u001B[0m copying lib/errorcodes.py -> build/lib.linux-x86_64-cpython-312/psycopg2\r\n",
      "  \u001B[31m   \u001B[0m copying lib/extensions.py -> build/lib.linux-x86_64-cpython-312/psycopg2\r\n",
      "  \u001B[31m   \u001B[0m copying lib/_ipaddress.py -> build/lib.linux-x86_64-cpython-312/psycopg2\r\n",
      "  \u001B[31m   \u001B[0m copying lib/__init__.py -> build/lib.linux-x86_64-cpython-312/psycopg2\r\n",
      "  \u001B[31m   \u001B[0m copying lib/errors.py -> build/lib.linux-x86_64-cpython-312/psycopg2\r\n",
      "  \u001B[31m   \u001B[0m copying lib/_range.py -> build/lib.linux-x86_64-cpython-312/psycopg2\r\n",
      "  \u001B[31m   \u001B[0m running build_ext\r\n",
      "  \u001B[31m   \u001B[0m building 'psycopg2._psycopg' extension\r\n",
      "  \u001B[31m   \u001B[0m creating build/temp.linux-x86_64-cpython-312/psycopg\r\n",
      "  \u001B[31m   \u001B[0m x86_64-linux-gnu-gcc -fno-strict-overflow -Wsign-compare -DNDEBUG -g -O2 -Wall -fPIC \"-DPSYCOPG_VERSION=2.9.10 (dt dec pq3 ext lo64)\" -DPSYCOPG_DEBUG=1 -DPG_VERSION_NUM=160008 -DHAVE_LO64=1 -DPSYCOPG_DEBUG=1 -I/home/kiwerkstatt/PycharmProjects/llama-rag/notebooks/venv/include -I/usr/include/python3.12 -I. -I/usr/include/postgresql -I/usr/include/postgresql/16/server -I/usr/include/libxml2 -c psycopg/adapter_asis.c -o build/temp.linux-x86_64-cpython-312/psycopg/adapter_asis.o -Wdeclaration-after-statement\r\n",
      "  \u001B[31m   \u001B[0m In file included from psycopg/adapter_asis.c:28:\r\n",
      "  \u001B[31m   \u001B[0m ./psycopg/psycopg.h:36:10: fatal error: libpq-fe.h: No such file or directory\r\n",
      "  \u001B[31m   \u001B[0m    36 | #include <libpq-fe.h>\r\n",
      "  \u001B[31m   \u001B[0m       |          ^~~~~~~~~~~~\r\n",
      "  \u001B[31m   \u001B[0m compilation terminated.\r\n",
      "  \u001B[31m   \u001B[0m \r\n",
      "  \u001B[31m   \u001B[0m It appears you are missing some prerequisite to build the package from source.\r\n",
      "  \u001B[31m   \u001B[0m \r\n",
      "  \u001B[31m   \u001B[0m You may install a binary package by installing 'psycopg2-binary' from PyPI.\r\n",
      "  \u001B[31m   \u001B[0m If you want to install psycopg2 from source, please install the packages\r\n",
      "  \u001B[31m   \u001B[0m required for the build and try again.\r\n",
      "  \u001B[31m   \u001B[0m \r\n",
      "  \u001B[31m   \u001B[0m For further information please check the 'doc/src/install.rst' file (also at\r\n",
      "  \u001B[31m   \u001B[0m <https://www.psycopg.org/docs/install.html>).\r\n",
      "  \u001B[31m   \u001B[0m \r\n",
      "  \u001B[31m   \u001B[0m error: command '/usr/bin/x86_64-linux-gnu-gcc' failed with exit code 1\r\n",
      "  \u001B[31m   \u001B[0m \u001B[31m[end of output]\u001B[0m\r\n",
      "  \r\n",
      "  \u001B[1;35mnote\u001B[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n",
      "\u001B[31m  ERROR: Failed building wheel for psycopg2\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\u001B[?25hFailed to build psycopg2\r\n",
      "\u001B[31mERROR: Could not build wheels for psycopg2, which is required to install pyproject.toml-based projects\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T12:08:59.576221Z",
     "start_time": "2025-03-20T12:08:55.194408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import uuid\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "def import_any_sql_to_postgres(dump_file,\n",
    "                              pg_host='localhost',\n",
    "                              pg_port='5432',\n",
    "                              pg_user='postgres',\n",
    "                              pg_password='',\n",
    "                              target_db=None):\n",
    "    \"\"\"\n",
    "    Import SQL dump from any source (MySQL/MariaDB/PostgreSQL) into PostgreSQL database.\n",
    "\n",
    "    Parameters:\n",
    "    - dump_file (str): Path to the SQL dump file\n",
    "    - pg_host (str): PostgreSQL host\n",
    "    - pg_port (str): PostgreSQL port\n",
    "    - pg_user (str): PostgreSQL username\n",
    "    - pg_password (str): PostgreSQL password\n",
    "    - target_db (str): Target database name (will be auto-generated if None)\n",
    "\n",
    "    Returns:\n",
    "    - str: Name of the created database\n",
    "    \"\"\"\n",
    "    # Check if dump file exists\n",
    "    if not os.path.isfile(dump_file):\n",
    "        raise FileNotFoundError(f\"SQL dump file not found: {dump_file}\")\n",
    "\n",
    "    # Generate database name if not provided\n",
    "    if not target_db:\n",
    "        target_db = f\"imported_db_{uuid.uuid4().hex[:6]}\"\n",
    "\n",
    "    # Setup database parameters\n",
    "    db_params = {\n",
    "        'host': pg_host,\n",
    "        'port': pg_port,\n",
    "        'user': pg_user,\n",
    "        'password': pg_password\n",
    "    }\n",
    "\n",
    "    # Create new database\n",
    "    create_database(db_params, target_db)\n",
    "\n",
    "    # Identify dump type\n",
    "    dump_type = identify_dump_type(dump_file)\n",
    "\n",
    "    # Import based on dump type\n",
    "    if dump_type == 'postgres':\n",
    "        success = import_postgres_dump(dump_file, db_params, target_db)\n",
    "    else:\n",
    "        success = import_mysql_dump(dump_file, db_params, target_db)\n",
    "\n",
    "    if success:\n",
    "        print(f\"Successfully imported {dump_type} dump into PostgreSQL database '{target_db}'\")\n",
    "    else:\n",
    "        print(f\"Failed to import {dump_type} dump into '{target_db}'\")\n",
    "\n",
    "    return target_db\n",
    "\n",
    "def identify_dump_type(dump_file):\n",
    "    \"\"\"Identify if the dump is from MySQL/MariaDB or PostgreSQL\"\"\"\n",
    "    try:\n",
    "        with open(dump_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            content = f.read(10000)  # Read first 10000 chars to identify\n",
    "\n",
    "            # PostgreSQL specific markers\n",
    "            if re.search(r'SET statement_timeout|SET lock_timeout|SET client_encoding|SET standard_conforming_strings', content):\n",
    "                return 'postgres'\n",
    "\n",
    "            # MySQL/MariaDB specific markers\n",
    "            if re.search(r'-- MySQL dump|-- MariaDB dump|ENGINE=|AUTO_INCREMENT=|DEFAULT CHARSET=', content):\n",
    "                return 'mysql'\n",
    "\n",
    "            # Additional check - MySQL typically uses backticks for identifiers\n",
    "            if '`' in content:\n",
    "                return 'mysql'\n",
    "\n",
    "            # Default to postgres if we can't determine\n",
    "            return 'postgres'\n",
    "    except Exception:\n",
    "        # If there's any issue reading or parsing the file\n",
    "        # Default to postgres\n",
    "        return 'postgres'\n",
    "\n",
    "def create_database(db_params, db_name):\n",
    "    \"\"\"Create a new database in PostgreSQL\"\"\"\n",
    "    # Connect to default database\n",
    "    conn_params = db_params.copy()\n",
    "    conn_params['dbname'] = 'postgres'  # Connect to default postgres db\n",
    "\n",
    "    conn = psycopg2.connect(**conn_params)\n",
    "    conn.autocommit = True\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Check if database exists\n",
    "    cursor.execute(sql.SQL(\"SELECT 1 FROM pg_database WHERE datname = %s\"), (db_name,))\n",
    "    if not cursor.fetchone():\n",
    "        cursor.execute(sql.SQL(\"CREATE DATABASE {}\").format(sql.Identifier(db_name)))\n",
    "        print(f\"Created database '{db_name}'\")\n",
    "    else:\n",
    "        print(f\"Database '{db_name}' already exists, using it\")\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "def convert_mysql_to_postgres(content):\n",
    "    \"\"\"Convert MySQL/MariaDB SQL syntax to PostgreSQL compatible syntax\"\"\"\n",
    "    # Replace backticks with double quotes for identifiers\n",
    "    content = re.sub(r'`([^`]*)`', r'\"\\1\"', content)\n",
    "\n",
    "    # Remove or replace MySQL/MariaDB specific syntax\n",
    "    content = re.sub(r'ENGINE\\s*=\\s*\\w+', '', content)\n",
    "    content = re.sub(r'AUTO_INCREMENT\\s*=\\s*\\d+', '', content)\n",
    "    content = re.sub(r'DEFAULT CHARSET\\s*=\\s*\\w+', '', content)\n",
    "    content = re.sub(r'COLLATE\\s*=\\s*\\w+', '', content)\n",
    "    content = re.sub(r'CHARACTER SET\\s*\\w+', '', content)\n",
    "\n",
    "    # Data types conversions\n",
    "    content = re.sub(r'int\\(\\d+\\)', 'integer', content)\n",
    "    content = re.sub(r'tinyint\\(\\d+\\)', 'smallint', content)\n",
    "    content = re.sub(r'mediumint\\(\\d+\\)', 'integer', content)\n",
    "    content = re.sub(r'bigint\\(\\d+\\)', 'bigint', content)\n",
    "    content = re.sub(r'varchar\\((\\d+)\\)', r'varchar(\\1)', content)\n",
    "    content = re.sub(r'UNSIGNED', '', content)\n",
    "\n",
    "    # Handle AUTO_INCREMENT\n",
    "    content = re.sub(r'AUTO_INCREMENT', 'SERIAL', content)\n",
    "\n",
    "    # Handle BOOLEAN values\n",
    "    content = re.sub(r\"b'0'\", 'false', content)\n",
    "    content = re.sub(r\"b'1'\", 'true', content)\n",
    "\n",
    "    # Additional common MySql functions\n",
    "    content = re.sub(r'IFNULL\\(', 'COALESCE(', content)\n",
    "\n",
    "    # Remove MySQL comment delimiters\n",
    "    content = re.sub(r'/\\*!.*?\\*/', '', content)\n",
    "\n",
    "    return content\n",
    "\n",
    "def import_mysql_dump(dump_file, db_params, db_name):\n",
    "    \"\"\"Import MySQL/MariaDB dump to PostgreSQL without pgloader\"\"\"\n",
    "    print(f\"Importing MySQL/MariaDB dump to PostgreSQL: {dump_file}\")\n",
    "\n",
    "    try:\n",
    "        with open(dump_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            sql_content = f.read()\n",
    "\n",
    "        # Convert MySQL syntax to PostgreSQL\n",
    "        sql_content = convert_mysql_to_postgres(sql_content)\n",
    "\n",
    "        # Split into executable statements\n",
    "        statements = re.split(r';[ \\t]*\\n', sql_content)\n",
    "\n",
    "        # Connect to the target database\n",
    "        conn_params = db_params.copy()\n",
    "        conn_params['dbname'] = db_name\n",
    "        conn = psycopg2.connect(**conn_params)\n",
    "        conn.autocommit = False\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Execute each statement\n",
    "        success_count = 0\n",
    "        total_statements = len(statements)\n",
    "        error_count = 0\n",
    "\n",
    "        for i, statement in enumerate(statements):\n",
    "            if statement.strip():\n",
    "                try:\n",
    "                    cursor.execute(statement)\n",
    "                    success_count += 1\n",
    "\n",
    "                    # Commit every 100 statements or when reaching the final one\n",
    "                    if success_count % 100 == 0 or i == total_statements - 1:\n",
    "                        conn.commit()\n",
    "                        print(f\"Progress: {success_count}/{total_statements} statements processed\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    error_count += 1\n",
    "                    print(f\"Error executing statement: {str(e)[:100]}...\")\n",
    "                    conn.rollback()  # Rollback the failed statement\n",
    "\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "        print(f\"Import completed: {success_count} statements succeeded, {error_count} failed\")\n",
    "        return error_count < total_statements * 0.5  # Consider successful if less than 50% failed\n",
    "    except Exception as e:\n",
    "        print(f\"Import failed with error: {e}\")\n",
    "        return False\n",
    "\n",
    "def import_postgres_dump(dump_file, db_params, db_name):\n",
    "    \"\"\"Import PostgreSQL dump to PostgreSQL\"\"\"\n",
    "    print(f\"Importing PostgreSQL dump: {dump_file}\")\n",
    "\n",
    "    # Set environment variable for password\n",
    "    env = os.environ.copy()\n",
    "    env['PGPASSWORD'] = db_params['password']\n",
    "\n",
    "    # Import using psql or pg_restore based on file type\n",
    "    try:\n",
    "        if dump_file.endswith('.dump') or dump_file.endswith('.backup'):\n",
    "            # Binary dump\n",
    "            cmd = [\n",
    "                'pg_restore',\n",
    "                '--no-owner',\n",
    "                '--no-privileges',\n",
    "                f\"--host={db_params['host']}\",\n",
    "                f\"--port={db_params['port']}\",\n",
    "                f\"--username={db_params['user']}\",\n",
    "                f\"--dbname={db_name}\",\n",
    "                dump_file\n",
    "            ]\n",
    "        else:\n",
    "            # Text dump (SQL file)\n",
    "            cmd = [\n",
    "                'psql',\n",
    "                f\"--host={db_params['host']}\",\n",
    "                f\"--port={db_params['port']}\",\n",
    "                f\"--username={db_params['user']}\",\n",
    "                f\"--dbname={db_name}\",\n",
    "                '--file', dump_file\n",
    "            ]\n",
    "\n",
    "        result = subprocess.run(cmd, env=env, capture_output=True, text=True)\n",
    "\n",
    "        # Print any output from the command\n",
    "        if result.stdout:\n",
    "            print(\"Output:\", result.stdout[:500], \"...\" if len(result.stdout) > 500 else \"\")\n",
    "        if result.stderr:\n",
    "            print(\"Errors/Warnings:\", result.stderr[:500], \"...\" if len(result.stderr) > 500 else \"\")\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Import using command-line tools failed: {e}\")\n",
    "\n",
    "        # Try direct SQL execution as fallback\n",
    "        try:\n",
    "            print(\"Trying direct SQL execution as fallback...\")\n",
    "            conn_params = db_params.copy()\n",
    "            conn_params['dbname'] = db_name\n",
    "            conn = psycopg2.connect(**conn_params)\n",
    "            conn.autocommit = True\n",
    "            cursor = conn.cursor()\n",
    "\n",
    "            with open(dump_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                sql_content = f.read()\n",
    "\n",
    "            cursor.execute(sql_content)\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "            return True\n",
    "        except Exception as e2:\n",
    "            print(f\"Direct SQL execution also failed: {e2}\")\n",
    "            return False\n",
    "\n",
    "# Example usage in Jupyter:\n",
    "db_name = import_any_sql_to_postgres('./data/customer.sql',\n",
    "                                    pg_host='localhost',\n",
    "                                    pg_user='postgres',\n",
    "                                    pg_password='password',\n",
    "                                     target_db=\"unique_db\")"
   ],
   "id": "1bfc65e2011fe19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'unique_db' already exists, using it\n",
      "Importing PostgreSQL dump: ./data/customer.sql\n",
      "Errors/Warnings: psql:data/customer.sql:16: ERROR:  relation \"customer\" already exists\n",
      "psql:data/customer.sql:18: ERROR:  null value in column \"id\" of relation \"customer\" violates not-null constraint\n",
      "DETAIL:  Failing row contains (null, Emilia Dunsford, Scott, edunsford0@canalblog.com, 838-232-1446).\n",
      "psql:data/customer.sql:19: ERROR:  null value in column \"id\" of relation \"customer\" violates not-null constraint\n",
      "DETAIL:  Failing row contains (null, Max McConnachie, Cambridge, mmcconnachie1@washingtonpost.com, 798 ...\n",
      "Successfully imported postgres dump into PostgreSQL database 'unique_db'\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T11:57:51.020112Z",
     "start_time": "2025-03-20T11:57:50.029331Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install pgloader",
   "id": "166dfc6e709b4150",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: Could not find a version that satisfies the requirement pgloader (from versions: none)\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\u001B[31mERROR: No matching distribution found for pgloader\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6aaf7f6b09c92e84"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
